{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25e65aa-da44-4eda-9490-48564acf945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/290.4 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 51.2/290.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 122.9/290.4 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 245.8/290.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0860294-5882-4bdd-9ec8-d7a00c2ca2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "pdf=PdfReader('Data Science and AI - Notes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f9142a-0ccf-4399-8354-84a7d593c0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d610c034-d373-4dee-ae5a-2d6763e878a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.aiquest.org  Prepared By:  \\nRashedul Alam Shakil  \\nWorks at Siemens, Germany  \\nFounder, aiQuest Intelligence  \\nFounder, Study Mart  \\n❖ Big Data Technologies:  \\nBig Data:  The size of the data is beyond the ability  of typical database software tools to capture, \\nstore, manage, and analyze. This might be data sizes of terabytes, petabytes, or even exabytes. The \\nspeed at which the data is created, collected, and processed is extremely high. This requires real -\\ntime proc essing and analysis. Examples include data from mobile devices, web applications, and \\nsensors involved in the Internet of Things (IoT).  \\nManaging big data involves various strategies and tools designed to handle the large volume, variety, \\nand velocity of data efficiently. Here’s a step -by-step breakdown of how big data can be managed \\neffectively:  \\n \\nStrategies for Managing Big Data:  \\n1. Data Collection:  \\n   - Efficient mechanisms for capturing and storing large volumes of data from diverse sources.  \\n2. Data Storage:  \\n   - Scalable storage solutions that can grow with data needs. This might involve distributed storage \\nsystems that can handle large volumes of data across many servers.  \\n3. Data Processing:  \\n   - High-performance processing systems to analyze and process data in real -time or in batch mode, \\ndepending on the application.  \\n4. Data Analysis:  \\n   - Advanced analytics tools and algorithms capable of extracting valuable insights from large and \\ncomplex datasets.  \\n5. Data Visualization:  \\n   - Tools that help in visualizing and interpreting the results of data analysis to make them \\ncomprehensible to decision -makers.  \\n6. Data Security and Governance:  \\n   - Ensuring data integrity, privacy, and compliance with regulations through robust security \\nmeasures and governance policies.  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=pdf.pages[0]\n",
    "page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69ce3097-b992-4a86-8402-cd855a68d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\tanjila\\anaconda3\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90907399-10a9-4267-9d48-e4f0fe2c4d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.aiquest.org  Prepared By:  \n",
      "Rashedul Alam Shakil  \n",
      "Works at Siemens, Germany  \n",
      "Founder, aiQuest Intelligence  \n",
      "Founder, Study Mart  \n",
      "❖ Big Data Technologies:  \n",
      "Big Data:  The size of the data is beyond the ability  of typical database software tools to capture, \n",
      "store, manage, and analyze. This might be data sizes of terabytes, petabytes, or even exabytes. The \n",
      "speed at which the data is created, collected, and processed is extremely high. This requires real -\n",
      "time proc essing and analysis. Examples include data from mobile devices, web applications, and \n",
      "sensors involved in the Internet of Things (IoT).  \n",
      "Managing big data involves various strategies and tools designed to handle the large volume, variety, \n",
      "and velocity of data efficiently. Here’s a step -by-step breakdown of how big data can be managed \n",
      "effectively:  \n",
      " \n",
      "Strategies for Managing Big Data:  \n",
      "1. Data Collection:  \n",
      "   - Efficient mechanisms for capturing and storing large volumes of data from diverse sources.  \n",
      "2. Data Storage:  \n",
      "   - Scalable storage solutions that can grow with data needs. This might involve distributed storage \n",
      "systems that can handle large volumes of data across many servers.  \n",
      "3. Data Processing:  \n",
      "   - High-performance processing systems to analyze and process data in real -time or in batch mode, \n",
      "depending on the application.  \n",
      "4. Data Analysis:  \n",
      "   - Advanced analytics tools and algorithms capable of extracting valuable insights from large and \n",
      "complex datasets.  \n",
      "5. Data Visualization:  \n",
      "   - Tools that help in visualizing and interpreting the results of data analysis to make them \n",
      "comprehensible to decision -makers.  \n",
      "6. Data Security and Governance:  \n",
      "   - Ensuring data integrity, privacy, and compliance with regulations through robust security \n",
      "measures and governance policies.  \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "path = 'Data Science and AI - Notes.pdf'\n",
    "with open(path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    first_page = reader.pages[0].extract_text()\n",
    "    print(first_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c282ba7-9d7c-477d-b08d-7409c92ee137",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:5\u001b[1;36m\u001b[0m\n\u001b[1;33m    for page in reader.pages:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "path='Data Science and AI - Notes.pdf'\n",
    "with open(path,'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "   for page in reader.pages:\n",
    "       text=page.extract_text()\n",
    "       print(text)\n",
    "       print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "363e8428-4c6a-4889-8cc9-1792411280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.aiquest.org  Prepared By:  \n",
      "Rashedul Alam Shakil  \n",
      "Works at Siemens, Germany  \n",
      "Founder, aiQuest Intelligence  \n",
      "Founder, Study Mart  \n",
      "❖ Big Data Technologies:  \n",
      "Big Data:  The size of the data is beyond the ability  of typical database software tools to capture, \n",
      "store, manage, and analyze. This might be data sizes of terabytes, petabytes, or even exabytes. The \n",
      "speed at which the data is created, collected, and processed is extremely high. This requires real -\n",
      "time proc essing and analysis. Examples include data from mobile devices, web applications, and \n",
      "sensors involved in the Internet of Things (IoT).  \n",
      "Managing big data involves various strategies and tools designed to handle the large volume, variety, \n",
      "and velocity of data efficiently. Here’s a step -by-step breakdown of how big data can be managed \n",
      "effectively:  \n",
      " \n",
      "Strategies for Managing Big Data:  \n",
      "1. Data Collection:  \n",
      "   - Efficient mechanisms for capturing and storing large volumes of data from diverse sources.  \n",
      "2. Data Storage:  \n",
      "   - Scalable storage solutions that can grow with data needs. This might involve distributed storage \n",
      "systems that can handle large volumes of data across many servers.  \n",
      "3. Data Processing:  \n",
      "   - High-performance processing systems to analyze and process data in real -time or in batch mode, \n",
      "depending on the application.  \n",
      "4. Data Analysis:  \n",
      "   - Advanced analytics tools and algorithms capable of extracting valuable insights from large and \n",
      "complex datasets.  \n",
      "5. Data Visualization:  \n",
      "   - Tools that help in visualizing and interpreting the results of data analysis to make them \n",
      "comprehensible to decision -makers.  \n",
      "6. Data Security and Governance:  \n",
      "   - Ensuring data integrity, privacy, and compliance with regulations through robust security \n",
      "measures and governance policies.  \n",
      "\n",
      "\n",
      "www.aiquest.org   \n",
      "Tools for Big Data Management : \n",
      "The following are some of the key tools and technologies used in various stages of big data \n",
      "management:  \n",
      "1. Data Collection and Integration:  \n",
      "   - Apache Kafka: A framework for high -throughput, real -time data ingestion.  \n",
      "   - Apache Flume: A service for efficiently collecting, aggregating, and moving large amounts of log \n",
      "data.  \n",
      "2. Data Storage:  \n",
      "   - Hadoop Distributed File System (HDFS):  A distributed file system designed to run on commodity \n",
      "hardware.  \n",
      "   - NoSQL databases:  Such as MongoDB, Cassandra, and HBase, which are designed for high \n",
      "scalability and flexibility.  \n",
      "3. Data Processing:  \n",
      "   - Apache Hadoop:  An ecosystem of open -source components that fundamentally uses a Hadoop \n",
      "MapReduce programming model for distributed computing.  \n",
      "   - Apache Spark:  An open-source unified analytics engine for large -scale data processing, with \n",
      "built-in modules for streaming, SQL, machine learning, and graph processing.  \n",
      "4. Data Analysis:  \n",
      "   - Apache Hive:  A data warehouse software that facilitates querying and managing large datasets \n",
      "residing in distributed storage.  \n",
      "   - Presto: A high-performance , distributed SQL query engine designed for interactive analytic \n",
      "queries against data sources of all sizes.  \n",
      "5. Data Visualization:  \n",
      "   - Tableau: A leading platform for business intelligence and data visualization, capable of handling \n",
      "large amounts of data.  \n",
      "   - Power BI:  A suite of business analytics tools that deliver insights throughout your organization.  \n",
      "6. Data Security and Governance:  \n",
      "   - Apache Ranger:  A framework to enable, monitor, and manage comprehensive data security \n",
      "across the Hadoop platform.  \n",
      "   - Apache Atlas:  Provides scalable governance for Enterprise Hadoop that is designed to effectively \n",
      "manage metadata.  \n",
      " \n",
      "\n",
      "\n",
      "www.aiquest.org  These tools and strategies together create an ecosystem capable of managing big data from its initial \n",
      "collection and storage to processing, analysis, and eventual use. Depending on specific needs and \n",
      "the nature of the data, different combinations of these tools can be employed to achieve optimal \n",
      "results.  \n",
      " \n",
      "❖ Machine Learning:  \n",
      "Machine learning is a subset of artificial intelligence (AI) that enables systems to learn from data, \n",
      "identify patterns, and make decisions with minimal human intervention. It involves training \n",
      "algorithms on a dataset, allowing them to improve their perfor mance on tasks without being explicitly \n",
      "programmed for those specific tasks.  \n",
      " \n",
      "Types of Machine Learning:  \n",
      "Machine learning can be broadly categorized into three types: supervised learning, unsupervised \n",
      "learning, and reinforcement learning. Here’s a closer look at each:  \n",
      "1. Supervised Learning  \n",
      "In supervised learning, the model is trained on a labeled dataset, which means that each example in \n",
      "the training set is paired with an output label. The goal is to learn mapping from inputs to outputs, \n",
      "which can then be used to predict outcomes on unseen d ata.  \n",
      "   - Examples:  \n",
      "     - Classification tasks:  Predicting whether an email is spam or not spam.  \n",
      "     - Regression tasks:  Estimating the selling price of houses based on features like size and location.  \n",
      " \n",
      "2. Unsupervised Learning  \n",
      "Unsupervised learning involves training models on data without labeled responses, aiming to \n",
      "discover the underlying patterns or structures in the data. The algorithm tries to learn the basic \n",
      "structure of the data to understand the data more deeply.  \n",
      "   - Examples:  \n",
      "     - Clustering:  Grouping customers into segments for targeted marketing.  \n",
      "     - Dimensionality Reduction:  Reducing the number of random variables under consideration, \n",
      "such as with Principal Component Analysis (PCA).  \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "www.aiquest.org  3. Reinforcement Learning  \n",
      "Reinforcement learning is a type of learning where an agent learns to behave in an environment by \n",
      "performing actions and seeing the results. It learns to achieve a goal in an uncertain, potentially \n",
      "complex environment.  \n",
      "   - Examples:  \n",
      "     - Gaming:  AlphaGo, which learned optimal strategies in the game of Go.  \n",
      "     - Robotics:  Robots learning to navigate through a physical world.  \n",
      " \n",
      "Additional Types of Machine Learning : \n",
      "There are also specialized forms of machine learning that blend elements of the primary types or \n",
      "focus on specific kinds of data processing:  \n",
      "- Semi-supervised Learning:  Uses both labeled and unlabeled data to improve learning accuracy. \n",
      "Often used when acquiring a fully labeled dataset is costly or impractical.  \n",
      "- Transfer Learning:  Involves taking a pre -trained model (on one task) and retraining it on a new \n",
      "dataset or task, leveraging the learned features.  \n",
      "- Deep Learning:  A subset of machine learning that uses deep neural networks  to model complex \n",
      "patterns and performance tasks that involve huge amounts of data.  \n",
      " \n",
      "Examples of Machine Learning Applications : \n",
      "- Predictive Analytics:  Using historical data to predict future outcomes, such as credit scoring.  \n",
      "- Natural Language Processing (NLP):  Applications like speech recognition, translation services, \n",
      "and chatbots.  \n",
      "- Computer Vision:  Image recognition and object detection systems, such as those used in \n",
      "autonomous vehicles.  \n",
      "Machine learning is integral to many modern applications, enabling systems to perform complex \n",
      "tasks like driving cars, managing investment portfolios, providing personalized recommendations, \n",
      "and much more, all by learning from data.  \n",
      " \n",
      "❖ Deep Learning:  \n",
      " Deep learning is a specialized subset of machine learning that involves neural networks with many \n",
      "layers, hence the term \"deep.\" These deep neural networks are designed to learn from vast amounts \n",
      "of data through architectures that mimic the way the human b rain operates. Deep learning models \n",
      "are particularly powerful because they can automatically discover the features to be used for \n",
      "classification or prediction, eliminating the need for manual feature extraction.  \n",
      "\n",
      "\n",
      "www.aiquest.org   \n",
      "Key Characteristics of Deep Learning:  \n",
      "1. Layered Structure:  Deep learning models consist of multiple layers through which data is \n",
      "processed, allowing the model to learn different levels of abstraction. These layers include input and \n",
      "output layers as well as multiple hidden layers.  \n",
      "2. Feature Hierarchy:  As data passes through the layers of a neural network, the model extracts \n",
      "features automatically, starting from simple features at earlier layers to more complex features at \n",
      "deeper layers.  \n",
      "3. High Computational Requirement:  Deep learning models typically require significant \n",
      "computational power, usually provided by GPUs (Graphics Processing Units) or specialized hardware \n",
      "like TPUs (Tensor Processing Units).  \n",
      "4. Large Data Sets:  They perform better with large data sets, harnessing the vast amount of data to \n",
      "improve their accuracy and efficacy over time.  \n",
      "5. End-to-end Learning:  These models are often trained end -to-end from raw data to outcomes, \n",
      "reducing the need for manual preprocessing and feature selection.  \n",
      " \n",
      "Examples of Deep Learning Applications:  \n",
      "1. Image Recognition:  Deep learning excels in tasks like facial recognition, medical image analysis, \n",
      "and classifying objects within an image. For example, platforms like Google Photos use deep learning \n",
      "to recognize faces and objects in photos, allowing for sophisticated search  capabilities.  \n",
      "2. Natural Language Processing (NLP):  Applications like machine translation, sentiment analysis, \n",
      "and text generation. Tools like GPT (Generative Pre -trained Transformer) and BERT (Bidirectional \n",
      "Encoder Representations from Transformers) are examples of deep learning models that have \n",
      "revolutio nized how machines understand and generate human language.  \n",
      "3. Autonomous Vehicles:  Self-driving cars use deep learning to make sense of their surroundings \n",
      "and make driving decisions. This includes recognizing traffic signs, detecting pedestrians, and \n",
      "navigating through complex environments.  \n",
      "4. Speech Recognition:  Virtual assistants like Siri, Alexa, and Google Assistant rely on deep learning \n",
      "for understanding and generating spoken language, enabling them to comprehend and respond to \n",
      "user requests.  \n",
      "5. Recommendation Systems:  Platforms like Netflix and Spotify use deep learning to analyze your \n",
      "past behavior and the behavior of others to recommend movies or music tailored to your \n",
      "preferences.  \n",
      "6. Gaming:  Deep learning has been used to train systems like DeepMind's AlphaGo and OpenAI's \n",
      "Dota 2 bots, which can play strategic games at levels surpassing human world champions.  \n",
      " \n",
      "\n",
      "\n",
      "www.aiquest.org  Deep learning's capability to handle and make sense of vast amounts of unstructured data has made \n",
      "it a foundational technology in many cutting -edge applications, from enhancing computer vision to \n",
      "powering complex autonomous systems.  \n",
      " \n",
      "❖ Python for Artificial Intelligence:  \n",
      "Python is a popular language for both machine learning and deep learning due to its simplicity and \n",
      "powerful libraries. Here's a detailed list of some of the most widely used Python libraries and \n",
      "frameworks for these purposes:  \n",
      "Machine Learning Libraries:  \n",
      "1. Scikit-learn  \n",
      "   - Purpose:  General machine learning  \n",
      "   - Features:  Provides a wide array of supervised and unsupervised learning algorithms. It is known \n",
      "for being accessible and efficient and is built upon NumPy, SciPy, and Matplotlib. Ideal for classic \n",
      "machine learning algorithms like linear regression, decision trees, clustering, and more.  \n",
      "   - Use Case:  Great for beginning with machine learning, doing standard tasks like classification, \n",
      "regression, or clustering on medium -sized datasets.  \n",
      "2. Pandas  \n",
      "   - Purpose:  Data manipulation and analysis  \n",
      "   - Features:  Offers data structures and operations for manipulating numerical tables and time \n",
      "series. It's indispensable for data preprocessing in machine learning.  \n",
      "   - Use Case:  Data wrangling and data cleaning.  \n",
      "3. NumPy  \n",
      "   - Purpose:  Numerical computing  \n",
      "   - Features:  Supports large, multi -dimensional arrays and matrices, along with a large collection of \n",
      "high-level mathematical functions to operate on these arrays.  \n",
      "   - Use Case:  Core library for scientific computing in Python, used for linear algebra calculations, \n",
      "which are central in machine learning.  \n",
      "4. Statsmodels  \n",
      "   - Purpose:  Statistical modeling  \n",
      "   - Features:  Provides classes and functions for the estimation of many different statistical models, \n",
      "as well as for conducting statistical tests and statistical data exploration.  \n",
      "   - Use Case:  Detailed statistical modeling, hypothesis testing, and data exploration.  \n",
      "\n",
      "\n",
      "www.aiquest.org   \n",
      "Deep Learning Frameworks:  \n",
      "1. TensorFlow  \n",
      "   - Purpose:  General deep learning  \n",
      "   - Features:  Developed by Google, it's capable of handling tasks that require heavy numerical \n",
      "computations and is widely used for training large -scale neural networks. Supports both CPUs and \n",
      "GPUs and has a flexible, comprehensive ecosystem of tools, libraries, and com munity resources that \n",
      "lets researchers push the state -of-the-art in ML, and developers easily build and deploy ML -powered \n",
      "applications.  \n",
      "   - Use Case:  From beginners to experts looking to develop and train DL models.  \n",
      "2. Keras  \n",
      "   - Purpose:  High-level neural networks API  \n",
      "   - Features:  Runs on top of TensorFlow, CNTk, or Theano. Designed for human beings, not \n",
      "machines, focusing on enabling fast experimentation.  \n",
      "   - Use Case:  Ideal for getting started with neural networks, prototyping easily and quickly.  \n",
      "3. PyTorch  \n",
      "   - Purpose:  General deep learning  \n",
      "   - Features:  Developed by Facebook's AI Research lab. Known for its flexibility and speed, especially \n",
      "in research and development. It supports dynamic computational graphs that change with every \n",
      "iteration, which is particularly useful in projects where conditional ope rations and loops are \n",
      "common.  \n",
      "   - Use Use Case:  Preferred for academic and research applications and has a reputation for being \n",
      "easier to debug.  \n",
      "These libraries and frameworks provide the backbone for a wide range of machine learning and deep \n",
      "learning applications, from simple regression models to complex neural networks capable of image \n",
      "recognition, natural language processing, and more. Each has its strengths and specific use cases, \n",
      "allowing developers and researchers to choose the best tool for their needs.  \n",
      " \n",
      "❖ TensorFlow.js for Deep Learning:  \n",
      "TensorFlow itself is primarily written in C++ and Python. However, there is a specific version of \n",
      "TensorFlow called TensorFlow.js  that is designed for JavaScript. TensorFlow.js enables machine \n",
      "learning models to run directly in the browser or Node.js environments. This allows for the \n",
      "development and execution of machine learning models directly on client -side applications, \n",
      "providing  opportunities for real -time data analysis and interaction without the need for data to leave \n",
      "the user's device.  \n",
      "\n",
      "\n",
      "www.aiquest.org   \n",
      "Here are some key points about TensorFlow.js:  \n",
      "- Client-Side ML:  It enables on -device machine learning, enhancing privacy and reducing the need \n",
      "for server -side computations.  \n",
      "- Interactivity : Since it runs in the browser, TensorFlow.js can be used to create interactive web \n",
      "applications that utilize machine learning for real -time decisions.  \n",
      "- Accessibility:  JavaScript is one of the most widely used programming languages, making \n",
      "TensorFlow's powerful machine learning capabilities accessible to a broader range of developers.  \n",
      "- Integration:  TensorFlow.js can be integrated with other web technologies, making it easier to deploy \n",
      "and use machine learning models within existing web applications.  \n",
      "TensorFlow for Python and TensorFlow.js for JavaScript are indeed different, catering to distinct \n",
      "runtime environments and use cases, though they are part of the same broader TensorFlow \n",
      "ecosystem.  TensorFlow.js brings the power of TensorFlow to JavaScript, allowing for innovative \n",
      "applications directly in web environments.  \n",
      " \n",
      "❖ Data Analytics:  \n",
      "Data analytics  refers to the process of examining data sets to conclude  the information they contain, \n",
      "increasingly with the aid of specialized systems and software. Data analytics techniques and \n",
      "processes are used to enhance productivity and business gain. It involves transforming, cleaning, \n",
      "and modeling data to discover usef ul information, suggesting  conclusions, and support decision -\n",
      "making.  \n",
      "Key Aspects of Data Analytics:  \n",
      "1. Data Collection:  \n",
      "   - Gathering raw data from various sources, which could include internal databases, customer \n",
      "feedback, online sources, financial reports, and more.  \n",
      "2. Data Processing:  \n",
      "   - Organizing and transforming the data into a more usable and manageable format. This might \n",
      "involve data cleaning to remove errors or inconsistencies.  \n",
      "3. Data Analysis:  \n",
      "   - Applying statistical or computational techniques to identify patterns, trends, or relationships \n",
      "within the data.  \n",
      "4. Data Visualization:  \n",
      "   - Presenting data using visual elements like charts, graphs, and maps to make the data easily \n",
      "understandable.  \n",
      "\n",
      "\n",
      "www.aiquest.org  5. Data Interpretation and Decision -Making: \n",
      "   - Making informed decisions based on the insights derived from the analyzed data.  \n",
      " \n",
      "Types of Data Analytics  \n",
      "1. Descriptive Analytics:  \n",
      "   - Focuses on summarizing what has happened in the past using historical data. It usually involves \n",
      "metrics like total revenue, average costs, or performance reports.  \n",
      "2. Diagnostic Analytics:  \n",
      "   - Looks at past performance to determine what happened and why. The focus is on identifying \n",
      "causes and effects using techniques like data mining and drill -down.  \n",
      " \n",
      "3. Predictive Analytics:  \n",
      "   - Uses statistical models and forecast techniques to understand the future and answer: “What \n",
      "could happen?” This involves identifying trends and patterns from current and historical data to \n",
      "predict future occurrences.  \n",
      "4. Prescriptive Analytics:  \n",
      "   - This type of analytics seeks to find the best course of action for a given situation. It involves \n",
      "algorithms and machine learning capabilities to recommend actions aimed at achieving specific \n",
      "outcomes.  \n",
      " \n",
      "Applications of Data Analytics:  \n",
      "- Business Intelligence:  Helping companies make better business decisions by showing present \n",
      "and historical data within their business context.  \n",
      "- Healthcare:  Analyzing patient data and treatment outcomes to make better decisions about \n",
      "patient care and health practices.  \n",
      "- Finance:  Assessing risk, detecting fraudulent activities, managing assets, and optimizing \n",
      "portfolios.  \n",
      "- Retail: Understanding customer behavior, optimizing product placements, and improving \n",
      "customer satisfaction.  \n",
      "- Manufacturing:  Enhancing production quality, managing supply chain operations, and optimizing \n",
      "resource usage.  \n",
      "\n",
      "\n",
      "www.aiquest.org  Data analytics has become an essential tool across various domains, enabling organizations to \n",
      "operate more effectively by providing detailed insights into operational performance, customer \n",
      "preferences, and market trends.  \n",
      " \n",
      "❖ General Data Analytics and Business Intelligence Tools:  \n",
      "1. Tableau  \n",
      "   - A powerful data visualization tool used for business intelligence. It enables users to create \n",
      "interactive and shareable dashboards that depict trends, variations, and density of the data in the \n",
      "form of graphs and charts.  \n",
      "2. Microsoft Power BI  \n",
      "   - A suite of business analytics tools that deliver insights throughout your organization. Connect to \n",
      "hundreds of data sources, simplify data prep, and drive ad hoc analysis.  \n",
      "3. Google Analytics  \n",
      "   - A web analytics service offered by Google that tracks and reports website traffic. It’s widely used \n",
      "for marketing and resource optimization.  \n",
      " \n",
      "Statistical Analysis Tools:  \n",
      "4. Python  \n",
      "   - A programming language that has become synonymous with data science, featuring powerful \n",
      "libraries for data manipulation and analysis like Pandas, NumPy, and Scikit -learn.  \n",
      "5. R  \n",
      "   - A programming language and software environment for statistical computing and graphics \n",
      "supported by the R Foundation for Statistical Computing. It is widely used among statisticians and \n",
      "data miners for developing statistical software and data analysis . \n",
      "6. SAS  \n",
      "   - A software suite developed by SAS Institute for advanced analytics, multivariate analysis, \n",
      "business intelligence, data management, and predictive analytics.  \n",
      " \n",
      "Data Processing and Advanced Analytics:  \n",
      "7. Apache Spark  \n",
      "   - An open-source unified analytics engine for large -scale data processing. It performs up to 100 \n",
      "times faster than Hadoop MapReduce for certain applications.  \n",
      "\n",
      "\n",
      "www.aiquest.org   \n",
      "Data Warehousing and ETL Tools:  \n",
      "8. Apache Hadoop  \n",
      "   - An open-source framework that supports the processing of large data sets in a distributed \n",
      "computing environment. It is used to scale up from a single server to thousands of machines.  \n",
      " \n",
      "9. Informatica PowerCenter  \n",
      "   - An enterprise extract, transform load (ETL), and data integration software. It allows businesses to \n",
      "collect data from a variety of sources, transform it according to business needs, and load it into a \n",
      "target data warehouse.  \n",
      "Database Management Systems : \n",
      "10. MySQL  \n",
      "    - An open -source relational database management system commonly used as a backend \n",
      "database for web applications and corporate environments as a cost -effective way to store data.  \n",
      "11. MongoDB  \n",
      "    - A NoSQL database known for its high performance, high availability, and easy scalability. It uses \n",
      "a document -oriented data model, which allows for varied data structures to be stored.  \n",
      "Specialized and Niche Tools  \n",
      "12. KNIME  \n",
      "    - A free and open -source data analytics, reporting, and integration platform that integrates various \n",
      "components for machine learning and data mining through its modular data pipelining concept.  \n",
      "13. QlikView  \n",
      "    - A business discovery platform that provides self -service business intelligence for all business \n",
      "users in organizations.  \n",
      "These tools are designed to cater to different aspects of the data analytics process, from data \n",
      "preparation and cleansing to advanced statistical analysis and visualization. Depending on the \n",
      "specific needs and data types, organizations might choose one or a combination of these tools to \n",
      "support their data analysis efforts.  \n",
      " \n",
      "▪ Join Our Facebook Community!  \n",
      "▪ Join Our LinkedIn Community!  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "path = 'Data Science and AI - Notes.pdf'\n",
    "with open(path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        print(text)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6452f-f118-4c6c-9032-261c1d6e48c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
